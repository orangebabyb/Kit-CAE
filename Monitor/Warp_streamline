# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: LicenseRef-NvidiaProprietary
#
# (版權聲明 ... )
#

#! Path:
#! source > extensions > omni.cae.algorihthms.warp > python > impl > algorithms.py

__all__ = ["Streamlines"]

#todo 加入效能監測所需的模組
# [--- ADD ---]
import time
import os
try:
    import psutil
except ImportError:
    psutil = None
    print("WARNING: psutil module not found. RAM usage will not be reported.")

try:
    from pynvml import (
        nvmlInit, nvmlShutdown, nvmlDeviceGetHandleByIndex,
        nvmlDeviceGetMemoryInfo, NVMLError
    )
except ImportError:
    nvmlInit = None
    print("WARNING: pynvml module not found. VRAM usage will not be reported.")
# [--- END ADD ---]


# from logging import getLogger # [--- REMOVED ---]

import numpy as np
import warp as wp
from omni.cae.algorithms.core import Algorithm
from omni.cae.data import IJKExtents, array_utils, progress, range_utils, usd_utils
from omni.cae.data.commands import ComputeIJKExtents, ConvertToPointCloud, Voxelize
from omni.cae.schema import cae
from pxr import Gf, Sdf, Usd, UsdGeom
from usdrt import Sdf as SdfRt
from usdrt import UsdGeom as UsdGeomRt
from usdrt import Vt as VtRt

from .streamline_vdb import advect_vector_field

# logger = getLogger(__name__) # [--- REMOVED ---]

#todo 效能監測輔助函式 (使用 print)
# [--- ADD ---]
_nvml_handle = None
_process = psutil.Process(os.getpid()) if psutil else None

def _init_profiling():
    global _nvml_handle
    if nvmlInit and _nvml_handle is None:
        try:
            nvmlInit()
            _nvml_handle = nvmlDeviceGetHandleByIndex(0)
            print("NVML Initialized for profiling.")
        except NVMLError as e:
            print(f"ERROR: Failed to initialize NVML for profiling: {e}")
            _nvml_handle = None

def _get_ram_usage():
    if _process:
        return _process.memory_info().rss
    return 0

def _get_vram_usage():
    if _nvml_handle:
        try:
            return nvmlDeviceGetMemoryInfo(_nvml_handle).used
        except NVMLError as e:
            print(f"WARNING: Could not query VRAM: {e}")
    return 0

def _format_bytes(b):
    if b < 1024**3:
        return f"{b / (1024**2):.2f} MB"
    else:
        return f"{b / (1024**3):.2f} GB"
# [--- END ADD ---]

class Streamlines(Algorithm):
    """Streamlines algorithm implementation using Warp."""

    _xform_ops = [
        "omni:fabric:localMatrix",
    ]

    def __init__(self, prim: Usd.Prim):
        super().__init__(prim, ["CaeAlgorithmsWarpStreamlinesAPI"])
        self._ns = "omni:cae:warp:streamlines"
        self._rel_tracker = usd_utils.ChangeTracker(self.stage)
        for p in self._xform_ops:
            self._rel_tracker.TrackAttribute(p)

    def needs_update(self, timeCode: Usd.TimeCode) -> bool:
        if super().needs_update(timeCode):
            return True
        seeds_targets = self.prim.GetRelationship(f"{self._ns}:seeds").GetForwardedTargets()
        for t in seeds_targets:
            if self._rel_tracker.PrimChanged(t):
                return True
        return False

    @staticmethod
    def apply_xform(prim: Usd.Prim, coords: np.ndarray) -> np.ndarray:
        _xform_cache = UsdGeom.XformCache(Usd.TimeCode.EarliestTime())
        matrix: Gf.Matrix4d = _xform_cache.GetLocalTransformation(prim)[0]
        if matrix:
            coords_h = np.hstack([coords, np.ones((coords.shape[0], 1))])
            coords_h = coords_h @ matrix
            coords = coords_h[:, :3]
        return coords

    async def execute(self, timeCode=None, force=True) -> None:
        await super().execute(timeCode, force)
        self._rel_tracker.ClearChanges()

    async def get_seeds(self, timeCode: Usd.TimeCode) -> wp.array:
        seeds_prim = usd_utils.get_target_prim(self.prim, f"{self._ns}:seeds")
        seeds_result = await ConvertToPointCloud.invoke(seeds_prim, [], timeCode)
        seeds = array_utils.as_numpy_array(seeds_result.points).astype(np.float32, copy=False)
        xformed_seed_pts = Streamlines.apply_xform(seeds_prim, seeds)
        return wp.array(xformed_seed_pts, dtype=wp.vec3f, copy=False)

    async def get_dataset(self, timeCode: Usd.TimeCode) -> tuple[wp.Volume, float]:
        dataset_prim = usd_utils.get_target_prim(self.prim, f"{self._ns}:dataset")
        maxResolution = usd_utils.get_attribute(self.prim, f"{self._ns}:maxResolution")
        velocity_field_names = usd_utils.get_target_field_names(self.prim, f"{self._ns}:velocity", dataset_prim)

        roi_prim: Usd.Prim = usd_utils.get_target_prim(self.prim, f"{self._ns}:roi", quiet=True)
        roi = usd_utils.get_bounds(roi_prim, timeCode, quiet=True)
        print(f"Using ROI: {roi}") # [--- CHANGED ---]

        with progress.ProgressContext("Computing ijkExtents", scale=0.1):
            ijk_extents: IJKExtents = await ComputeIJKExtents.invoke(
                dataset_prim, [maxResolution] * 3, roi=roi, timeCode=timeCode
            )
            voxel_size = ijk_extents.spacing[0]

        if len(velocity_field_names) not in (1, 3):
            raise usd_utils.QuietableException("Invalid number of velocity fields specified!")

        with progress.ProgressContext("Voxelizing", shift=0.1, scale=0.9):
            volume = await Voxelize.invoke(
                dataset_prim,
                velocity_field_names,
                bbox=ijk_extents.getRange(),
                voxel_size=voxel_size,
                device_ordinal=0,
                timeCode=timeCode,
            )
        assert volume is not None
        return volume, voxel_size

    async def execute_impl(self, timeCode: Usd.TimeCode) -> bool:

        #todo 總體監測開始
        # [--- MODIFIED ---]
        _init_profiling()
        print("[omni.cae.algorithm.warp / impl / algorithm]")
        print("\n--- [Warp Streamline TOTAL (execute_impl) Profiling START] ---")
        total_start_time = time.perf_counter()
        ram_start = _get_ram_usage()
        vram_start = _get_vram_usage()
        print(f"[Warp Total] Initial RAM: {_format_bytes(ram_start)}")
        print(f"[Warp Total] Initial VRAM: {_format_bytes(vram_start)}")
        print("start executing streamlines (NanoVDB)")
        # [--- END MODIFIED ---]

        #
        #
        dX: float = usd_utils.get_attribute(self.prim, f"{self._ns}:dX")
        maxLength: int = usd_utils.get_attribute(self.prim, f"{self._ns}:maxLength")
        width: float = usd_utils.get_attribute(self.prim, f"{self._ns}:width")
        _ = usd_utils.get_target_prim(self.prim, f"{self._ns}:dataset")
        _ = usd_utils.get_target_prim(self.prim, f"{self._ns}:seeds")
        _ = usd_utils.get_target_prims(self.prim, f"{self._ns}:velocity")

        if dX <= 0.00001:
            raise RuntimeError(f"Invalid dX '{dX}'")
        if maxLength < 10:
            raise RuntimeError(f"Invalid maxLength '{maxLength}'")

        #todo --- Seeds[start] ---
        stage1_start = time.perf_counter()
        with progress.ProgressContext("Reading seeds", scale=0.1):
            seeds: wp.array = await self.get_seeds(timeCode)
        stage1_time = time.perf_counter() - stage1_start
        # [--- ADD ---]
        ram_after_s1 = _get_ram_usage()
        vram_after_s1 = _get_vram_usage()


        #todo --- Dataset (Voxelize)[start] ---
        stage2_start = time.perf_counter()
        with progress.ProgressContext("Reading dataset", shift=0.1, scale=0.8):
            dataset, voxel_size = await self.get_dataset(timeCode)
        stage2_time = time.perf_counter() - stage2_start
        # [--- ADD ---]
        ram_after_s2 = _get_ram_usage()
        vram_after_s2 = _get_vram_usage()


        #todo --- Advection[start] ---
        stage3_start = time.perf_counter()
        with progress.ProgressContext("Advecting", shift=0.9, scale=0.1):
            paths, scalars = advect_vector_field(
                initial_points=seeds, vdb=dataset, dt=dX * voxel_size, num_steps=maxLength
            )
        stage3_time = time.perf_counter() - stage3_start
        # [--- ADD ---]
        ram_after_s3 = _get_ram_usage()
        vram_after_s3 = _get_vram_usage()


        #todo --- USD ---
        stage4_start = time.perf_counter()
        curves = UsdGeomRt.BasisCurves(self.prim_rt)
        curves.CreatePointsAttr().Set(VtRt.Vec3fArray(paths.numpy()))
        curves.CreateCurveVertexCountsAttr().Set(
            VtRt.IntArray(np.full(shape=(seeds.shape[0], 1), fill_value=maxLength, dtype=np.intc))
        )
        curves.CreateWidthsAttr().Set([(width)])

        primvarsApi = UsdGeomRt.PrimvarsAPI(self.prim_rt)
        if scalars:
            scalars = scalars.numpy()
            primvarsApi.GetPrimvar("scalar").Set(VtRt.FloatArray(scalars.reshape(-1, 1)))
        else:
            primvarsApi.GetPrimvar("scalar").Set(
                VtRt.FloatArray(np.full(paths.shape[0], 0.0, dtype=np.float32).reshape(-1, 1))
            )

        if shader := self.get_surface_shader("ScalarColor", "mdl"):
            shader.CreateInput("enable_coloring", Sdf.ValueTypeNames.Bool).Set(scalars is not None)
            await range_utils.compute_and_set_range(shader.CreateInput("domain", Sdf.ValueTypeNames.Float2), scalars)
        else:
            print("WARNING: ScalarColor material not found") # [--- CHANGED ---]

        print("done executing streamlines") # [--- CHANGED ---]
        stage4_time = time.perf_counter() - stage4_start

        # [--- ADD ---]
        ram_after_s4 = _get_ram_usage()
        vram_after_s4 = _get_vram_usage()


        #todo 總體監測結束
        # [--- MODIFIED ---]
        total_end_time = time.perf_counter()

        print("--- [Warp Streamline TOTAL (execute_impl) Profiling END] ---")
        print(f"[Warp Total] STAGE 1 (Get Seeds):   {stage1_time:.4f} seconds")
        print(f"[Warp Total] STAGE 2 (Get Dataset): {stage2_time:.4f} seconds (Voxelization)")
        print(f"[Warp Total] STAGE 3 (Advection):   {stage3_time:.4f} seconds (Warp Kernel)")
        print(f"[Warp Total] STAGE 4 (Update USD):  {stage4_time:.4f} seconds")
        print("--------------------------------------------------")
        #
        #
        print(f"            |    RAM (Delta) |   VRAM (Delta)")
        print(f"After S1:   | {_format_bytes(ram_after_s1 - ram_start):>14s} | {_format_bytes(vram_after_s1 - vram_start):>14s}")
        print(f"After S2:   | {_format_bytes(ram_after_s2 - ram_start):>14s} | {_format_bytes(vram_after_s2 - vram_start):>14s}")
        print(f"After S3:   | {_format_bytes(ram_after_s3 - ram_start):>14s} | {_format_bytes(vram_after_s3 - vram_start):>14s}")
        print(f"After S4:   | {_format_bytes(ram_after_s4 - ram_start):>14s} | {_format_bytes(vram_after_s4 - vram_start):>14s}")
        print("--------------------------------------------------")
        print(f"[Warp Total] Total execution time: {total_end_time - total_start_time:.4f} seconds")
        print(f"[WSarp Total] Final RAM: {_format_bytes(ram_after_s4)}")
        print(f"[Warp Total] Final VRAM: {_format_bytes(vram_after_s4)}")
        print(f"[Warp Total] RAM Delta (Total): {_format_bytes(ram_after_s4 - ram_start)} (Used)")
        print(f"[Warp Total] VRAM Delta (Total): {_format_bytes(vram_after_s4 - vram_start)} (Used)")
        print("--------------------------------------------------\n")
        # [--- END MODIFIED ---]

        return True
